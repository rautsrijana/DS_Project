{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36149df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our Pkgs\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7bdc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/24 16:30:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/24 16:30:25 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(master='local[2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd6e13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.40.20:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f1ffdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pkgs \n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822a896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark\n",
    "spark = SparkSession.builder.appName(\"EmotionClassifierwithSpark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb2cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our dataset\n",
    "df = spark.read.csv(\"data/emotion_dataset_2.csv\",header=True,inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ec373c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n",
      "+---+--------+--------------------+--------------------+\n",
      "|_c0| Emotion|                Text|          Clean_Text|\n",
      "+---+--------+--------------------+--------------------+\n",
      "|  0| neutral|              Why ? |                null|\n",
      "|  1|     joy|Sage Act upgrade ...|Sage Act upgrade ...|\n",
      "|  2| sadness|ON THE WAY TO MY ...|WAY HOMEGIRL BABY...|\n",
      "|  3|     joy| Such an eye ! Th...|eye  true hazel e...|\n",
      "|  4|     joy|@Iluvmiasantos ug...|  ugh babe hugggz...|\n",
      "|  5|    fear|I'm expecting an ...|Im expecting extr...|\n",
      "|  6| sadness| .Couldnt wait to...|Couldnt wait live...|\n",
      "|  7|surprise|maken Tip 2: Stop...|maken Tip 2: Stop...|\n",
      "|  8|surprise|En dan krijg je f...|En dan krijg je f...|\n",
      "|  9|surprise| @1116am Drummer ...|  Drummer Boy bij...|\n",
      "| 10|   anger|\"The bull tossed ...|bull tossed effig...|\n",
      "| 11| sadness|People hide their...|People hide #fake...|\n",
      "| 12|     joy|For once in his l...|life  Leopold tru...|\n",
      "| 13|    fear|Against the assau...|assault laughter ...|\n",
      "| 14|   anger| With everything ...|         everybody  |\n",
      "| 15| sadness|Shakuhachi dress ...|Shakuhachi dress ...|\n",
      "| 16|surprise|Haha of course I ...|Haha course come ...|\n",
      "| 17|     joy|I have a feeling ...|feeling fail fren...|\n",
      "| 18|     joy| Good.Let ' s go ...|           GoodLet  |\n",
      "| 19|surprise|@JuliaLeader I re...|  reeeeeellllyyyy...|\n",
      "+---+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5515f438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_c0', 'Emotion', 'Text', 'Clean_Text']\n"
     ]
    }
   ],
   "source": [
    "# check for columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9477efcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'),\n",
       " ('Emotion', 'string'),\n",
       " ('Text', 'string'),\n",
       " ('Clean_Text', 'string')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for datatypes\n",
    "# Before InferSchema=True\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12bb15ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Emotion: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Clean_Text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for the Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06745cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------+--------------------+--------------------+\n",
      "|summary|               _c0| Emotion|                Text|          Clean_Text|\n",
      "+-------+------------------+--------+--------------------+--------------------+\n",
      "|  count|             34792|   34792|               34792|               34326|\n",
      "|   mean|           17395.5|    null|                12.0|   45372.84210526316|\n",
      "| stddev|10043.729619352896|    null|                null|   196466.3585619299|\n",
      "|    min|                 0|   anger|     !!!1!  Merry...|                    |\n",
      "|    max|             34791|surprise| RT “@jamiedorsc...| RT “  #ThatAwkw...|\n",
      "+-------+------------------+--------+--------------------+--------------------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Descriptive summary\n",
    "print(df.describe().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da37e2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "| Emotion|count|\n",
      "+--------+-----+\n",
      "|   shame|  146|\n",
      "|     joy|11045|\n",
      "| neutral| 2254|\n",
      "|   anger| 4297|\n",
      "|    fear| 5410|\n",
      "|surprise| 4062|\n",
      "| sadness| 6722|\n",
      "| disgust|  856|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Value Count \n",
    "df.groupBy('Emotion').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27888359",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f00891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85b3720a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Estimator',\n",
       " 'Model',\n",
       " 'Pipeline',\n",
       " 'PipelineModel',\n",
       " 'PredictionModel',\n",
       " 'Predictor',\n",
       " 'Transformer',\n",
       " 'UnaryTransformer',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'base',\n",
       " 'classification',\n",
       " 'clustering',\n",
       " 'common',\n",
       " 'evaluation',\n",
       " 'feature',\n",
       " 'fpm',\n",
       " 'image',\n",
       " 'linalg',\n",
       " 'param',\n",
       " 'pipeline',\n",
       " 'recommendation',\n",
       " 'regression',\n",
       " 'stat',\n",
       " 'tree',\n",
       " 'tuning',\n",
       " 'util',\n",
       " 'wrapper']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pyspark.ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edbb5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13bd48cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'Binarizer',\n",
       " 'BucketedRandomProjectionLSH',\n",
       " 'BucketedRandomProjectionLSHModel',\n",
       " 'Bucketizer',\n",
       " 'ChiSqSelector',\n",
       " 'ChiSqSelectorModel',\n",
       " 'CountVectorizer',\n",
       " 'CountVectorizerModel',\n",
       " 'DCT',\n",
       " 'DataFrame',\n",
       " 'DenseMatrix',\n",
       " 'DenseVector',\n",
       " 'Dict',\n",
       " 'ElementwiseProduct',\n",
       " 'FeatureHasher',\n",
       " 'Generic',\n",
       " 'HasFeaturesCol',\n",
       " 'HasHandleInvalid',\n",
       " 'HasInputCol',\n",
       " 'HasInputCols',\n",
       " 'HasLabelCol',\n",
       " 'HasMaxIter',\n",
       " 'HasNumFeatures',\n",
       " 'HasOutputCol',\n",
       " 'HasOutputCols',\n",
       " 'HasRelativeError',\n",
       " 'HasSeed',\n",
       " 'HasStepSize',\n",
       " 'HasThreshold',\n",
       " 'HasThresholds',\n",
       " 'HashingTF',\n",
       " 'IDF',\n",
       " 'IDFModel',\n",
       " 'Imputer',\n",
       " 'ImputerModel',\n",
       " 'IndexToString',\n",
       " 'Interaction',\n",
       " 'JM',\n",
       " 'JavaEstimator',\n",
       " 'JavaMLReadable',\n",
       " 'JavaMLWritable',\n",
       " 'JavaModel',\n",
       " 'JavaParams',\n",
       " 'JavaTransformer',\n",
       " 'List',\n",
       " 'MaxAbsScaler',\n",
       " 'MaxAbsScalerModel',\n",
       " 'MinHashLSH',\n",
       " 'MinHashLSHModel',\n",
       " 'MinMaxScaler',\n",
       " 'MinMaxScalerModel',\n",
       " 'NGram',\n",
       " 'Normalizer',\n",
       " 'OneHotEncoder',\n",
       " 'OneHotEncoderModel',\n",
       " 'Optional',\n",
       " 'P',\n",
       " 'PCA',\n",
       " 'PCAModel',\n",
       " 'Param',\n",
       " 'Params',\n",
       " 'PolynomialExpansion',\n",
       " 'QuantileDiscretizer',\n",
       " 'RFormula',\n",
       " 'RFormulaModel',\n",
       " 'RegexTokenizer',\n",
       " 'RobustScaler',\n",
       " 'RobustScalerModel',\n",
       " 'SQLTransformer',\n",
       " 'SparkContext',\n",
       " 'StandardScaler',\n",
       " 'StandardScalerModel',\n",
       " 'StopWordsRemover',\n",
       " 'StringIndexer',\n",
       " 'StringIndexerModel',\n",
       " 'TYPE_CHECKING',\n",
       " 'Tokenizer',\n",
       " 'Tuple',\n",
       " 'TypeConverters',\n",
       " 'TypeVar',\n",
       " 'Union',\n",
       " 'UnivariateFeatureSelector',\n",
       " 'UnivariateFeatureSelectorModel',\n",
       " 'VarianceThresholdSelector',\n",
       " 'VarianceThresholdSelectorModel',\n",
       " 'Vector',\n",
       " 'VectorAssembler',\n",
       " 'VectorIndexer',\n",
       " 'VectorIndexerModel',\n",
       " 'VectorSizeHint',\n",
       " 'VectorSlicer',\n",
       " 'Word2Vec',\n",
       " 'Word2VecModel',\n",
       " '_BucketedRandomProjectionLSHParams',\n",
       " '_CountVectorizerParams',\n",
       " '_IDFParams',\n",
       " '_ImputerParams',\n",
       " '_LSH',\n",
       " '_LSHModel',\n",
       " '_LSHParams',\n",
       " '_MaxAbsScalerParams',\n",
       " '_MinMaxScalerParams',\n",
       " '_OneHotEncoderParams',\n",
       " '_PCAParams',\n",
       " '_RFormulaParams',\n",
       " '_RobustScalerParams',\n",
       " '_Selector',\n",
       " '_SelectorModel',\n",
       " '_SelectorParams',\n",
       " '_StandardScalerParams',\n",
       " '_StringIndexerParams',\n",
       " '_UnivariateFeatureSelectorParams',\n",
       " '_VarianceThresholdSelectorParams',\n",
       " '_VectorIndexerParams',\n",
       " '_Word2VecParams',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_convert_to_vector',\n",
       " '_jvm',\n",
       " 'cast',\n",
       " 'inherit_doc',\n",
       " 'keyword_only',\n",
       " 'overload',\n",
       " 'since']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pyspark.ml.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b0dc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "524092b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Differen Stages For the pipline\n",
    "tokenizer = Tokenizer(inputCol='Text', outputCol='token_text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "099eb5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_remover = StopWordsRemover(inputCol='token_text',outputCol='filter_token')\n",
    "vectorizer = CountVectorizer(inputCol='filter_token',outputCol='raw_Features')\n",
    "idf = IDF(inputCol='raw_Features',outputCol='vectorized_Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "033d84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoding/LabelIndexing\n",
    "labelEncoder = StringIndexer(inputCol='Emotion',outputCol='label').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0932faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n",
      "+---+-------+--------------------+--------------------+-----+\n",
      "|_c0|Emotion|                Text|          Clean_Text|label|\n",
      "+---+-------+--------------------+--------------------+-----+\n",
      "|  0|neutral|              Why ? |                null|  5.0|\n",
      "|  1|    joy|Sage Act upgrade ...|Sage Act upgrade ...|  0.0|\n",
      "|  2|sadness|ON THE WAY TO MY ...|WAY HOMEGIRL BABY...|  1.0|\n",
      "|  3|    joy| Such an eye ! Th...|eye  true hazel e...|  0.0|\n",
      "|  4|    joy|@Iluvmiasantos ug...|  ugh babe hugggz...|  0.0|\n",
      "+---+-------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelEncoder.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5591302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy', 'sadness', 'fear', 'anger', 'surprise', 'neutral', 'disgust', 'shame']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEncoder.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5d1da76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n",
      "+---+-------+--------------------+--------------------+-----+\n",
      "|_c0|Emotion|                Text|          Clean_Text|label|\n",
      "+---+-------+--------------------+--------------------+-----+\n",
      "|  0|neutral|              Why ? |                null|  5.0|\n",
      "|  1|    joy|Sage Act upgrade ...|Sage Act upgrade ...|  0.0|\n",
      "|  2|sadness|ON THE WAY TO MY ...|WAY HOMEGIRL BABY...|  1.0|\n",
      "|  3|    joy| Such an eye ! Th...|eye  true hazel e...|  0.0|\n",
      "|  4|    joy|@Iluvmiasantos ug...|  ugh babe hugggz...|  0.0|\n",
      "+---+-------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = labelEncoder.transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8264a68",
   "metadata": {},
   "source": [
    "## Train_Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "892453fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split Dataset\n",
    "(train,test) = df.randomSplit((0.8,0.2),seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4c9d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n",
      "+---+-------+--------------------+--------------------+-----+\n",
      "|_c0|Emotion|                Text|          Clean_Text|label|\n",
      "+---+-------+--------------------+--------------------+-----+\n",
      "|  0|neutral|              Why ? |                null|  5.0|\n",
      "|  1|    joy|Sage Act upgrade ...|Sage Act upgrade ...|  0.0|\n",
      "|  3|    joy| Such an eye ! Th...|eye  true hazel e...|  0.0|\n",
      "|  4|    joy|@Iluvmiasantos ug...|  ugh babe hugggz...|  0.0|\n",
      "|  5|   fear|I'm expecting an ...|Im expecting extr...|  2.0|\n",
      "+---+-------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f26cb6",
   "metadata": {},
   "source": [
    "### Train Data Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c95b2239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n",
      "+--------+-----+\n",
      "| Emotion|count|\n",
      "+--------+-----+\n",
      "|   shame|  110|\n",
      "|     joy| 8795|\n",
      "| neutral| 1817|\n",
      "|   anger| 3444|\n",
      "|    fear| 4332|\n",
      "|surprise| 3257|\n",
      "| sadness| 5427|\n",
      "| disgust|  683|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Value Count \n",
    "train.groupBy('Emotion').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf3a98",
   "metadata": {},
   "source": [
    "### Test Data Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "722643ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n",
      "+--------+-----+\n",
      "| Emotion|count|\n",
      "+--------+-----+\n",
      "|   shame|   36|\n",
      "|     joy| 2250|\n",
      "| neutral|  437|\n",
      "|   anger|  853|\n",
      "|    fear| 1078|\n",
      "|surprise|  805|\n",
      "| sadness| 1295|\n",
      "| disgust|  173|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Value Count \n",
    "test.groupBy('Emotion').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254b5bae",
   "metadata": {},
   "source": [
    "### Estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe3e5a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABCMeta',\n",
       " 'Any',\n",
       " 'ArrayType',\n",
       " 'BinaryLogisticRegressionSummary',\n",
       " 'BinaryLogisticRegressionTrainingSummary',\n",
       " 'BinaryRandomForestClassificationSummary',\n",
       " 'BinaryRandomForestClassificationTrainingSummary',\n",
       " 'CM',\n",
       " 'ClassificationModel',\n",
       " 'Classifier',\n",
       " 'DataFrame',\n",
       " 'DecisionTreeClassificationModel',\n",
       " 'DecisionTreeClassifier',\n",
       " 'DecisionTreeRegressionModel',\n",
       " 'DefaultParamsReader',\n",
       " 'DefaultParamsWriter',\n",
       " 'Dict',\n",
       " 'DoubleType',\n",
       " 'Estimator',\n",
       " 'FMClassificationModel',\n",
       " 'FMClassificationSummary',\n",
       " 'FMClassificationTrainingSummary',\n",
       " 'FMClassifier',\n",
       " 'GBTClassificationModel',\n",
       " 'GBTClassifier',\n",
       " 'Generic',\n",
       " 'HasAggregationDepth',\n",
       " 'HasBlockSize',\n",
       " 'HasElasticNetParam',\n",
       " 'HasFitIntercept',\n",
       " 'HasMaxBlockSizeInMB',\n",
       " 'HasMaxIter',\n",
       " 'HasParallelism',\n",
       " 'HasProbabilityCol',\n",
       " 'HasRawPredictionCol',\n",
       " 'HasRegParam',\n",
       " 'HasSeed',\n",
       " 'HasSolver',\n",
       " 'HasStandardization',\n",
       " 'HasStepSize',\n",
       " 'HasThreshold',\n",
       " 'HasThresholds',\n",
       " 'HasTol',\n",
       " 'HasTrainingSummary',\n",
       " 'HasWeightCol',\n",
       " 'Iterable',\n",
       " 'JPM',\n",
       " 'JavaMLReadable',\n",
       " 'JavaMLReader',\n",
       " 'JavaMLWritable',\n",
       " 'JavaMLWriter',\n",
       " 'JavaParams',\n",
       " 'JavaPredictionModel',\n",
       " 'JavaPredictor',\n",
       " 'JavaWrapper',\n",
       " 'LinearSVC',\n",
       " 'LinearSVCModel',\n",
       " 'LinearSVCSummary',\n",
       " 'LinearSVCTrainingSummary',\n",
       " 'List',\n",
       " 'LogisticRegression',\n",
       " 'LogisticRegressionModel',\n",
       " 'LogisticRegressionSummary',\n",
       " 'LogisticRegressionTrainingSummary',\n",
       " 'MLReadable',\n",
       " 'MLReader',\n",
       " 'MLWritable',\n",
       " 'MLWriter',\n",
       " 'Matrix',\n",
       " 'Model',\n",
       " 'MultilayerPerceptronClassificationModel',\n",
       " 'MultilayerPerceptronClassificationSummary',\n",
       " 'MultilayerPerceptronClassificationTrainingSummary',\n",
       " 'MultilayerPerceptronClassifier',\n",
       " 'NaiveBayes',\n",
       " 'NaiveBayesModel',\n",
       " 'OneVsRest',\n",
       " 'OneVsRestModel',\n",
       " 'OneVsRestModelReader',\n",
       " 'OneVsRestModelWriter',\n",
       " 'OneVsRestReader',\n",
       " 'OneVsRestWriter',\n",
       " 'Optional',\n",
       " 'Param',\n",
       " 'Params',\n",
       " 'PredictionModel',\n",
       " 'Predictor',\n",
       " 'ProbabilisticClassificationModel',\n",
       " 'ProbabilisticClassifier',\n",
       " 'RandomForestClassificationModel',\n",
       " 'RandomForestClassificationSummary',\n",
       " 'RandomForestClassificationTrainingSummary',\n",
       " 'RandomForestClassifier',\n",
       " 'Row',\n",
       " 'SparkContext',\n",
       " 'StorageLevel',\n",
       " 'T',\n",
       " 'TYPE_CHECKING',\n",
       " 'ThreadPool',\n",
       " 'Type',\n",
       " 'TypeConverters',\n",
       " 'TypeVar',\n",
       " 'Union',\n",
       " 'Vector',\n",
       " 'VectorUDT',\n",
       " 'Vectors',\n",
       " '_BinaryClassificationSummary',\n",
       " '_ClassificationSummary',\n",
       " '_ClassifierParams',\n",
       " '_DecisionTreeClassifierParams',\n",
       " '_DecisionTreeModel',\n",
       " '_DecisionTreeParams',\n",
       " '_FactorizationMachinesParams',\n",
       " '_GBTClassifierParams',\n",
       " '_GBTParams',\n",
       " '_HasVarianceImpurity',\n",
       " '_JavaClassificationModel',\n",
       " '_JavaClassifier',\n",
       " '_JavaProbabilisticClassificationModel',\n",
       " '_JavaProbabilisticClassifier',\n",
       " '_LinearSVCParams',\n",
       " '_LogisticRegressionParams',\n",
       " '_MultilayerPerceptronParams',\n",
       " '_NaiveBayesParams',\n",
       " '_OneVsRestParams',\n",
       " '_OneVsRestSharedReadWrite',\n",
       " '_PredictorParams',\n",
       " '_ProbabilisticClassifierParams',\n",
       " '_RandomForestClassifierParams',\n",
       " '_RandomForestParams',\n",
       " '_TrainingSummary',\n",
       " '_TreeClassifierParams',\n",
       " '_TreeEnsembleModel',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'abstractmethod',\n",
       " 'cast',\n",
       " 'inherit_doc',\n",
       " 'inheritable_thread_target',\n",
       " 'keyword_only',\n",
       " 'operator',\n",
       " 'os',\n",
       " 'overload',\n",
       " 'since',\n",
       " 'sys',\n",
       " 'udf',\n",
       " 'uuid',\n",
       " 'warnings',\n",
       " 'when']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pyspark.ml.classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3448189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estimator\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3aeefdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized features are coming from the last line of Pipelines above.\n",
    "nb = NaiveBayes(featuresCol='raw_Features',labelCol='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c5c84",
   "metadata": {},
   "source": [
    "## Building a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48c3db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5558456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer,stopwords_remover,vectorizer,nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "074be6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Param(parent='Pipeline_7828915668f1', name='stages', doc='a list of pipeline stages')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c289a231",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "163772d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Building MOdel\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af0694d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_490403737495"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c73b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10debc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on our Test Dataset\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7de0281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:49 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "22/11/24 16:30:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n",
      "22/11/24 16:30:49 WARN InstanceBuilder$JavaBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "+---+--------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|_c0| Emotion|                Text|          Clean_Text|label|          token_text|        filter_token|        raw_Features|       rawPrediction|         probability|prediction|\n",
      "+---+--------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  2| sadness|ON THE WAY TO MY ...|WAY HOMEGIRL BABY...|  1.0|[on, the, way, to...|[way, homegirl, b...|(49719,[24,60,81,...|[-69.525503433815...|[0.60336336801864...|       0.0|\n",
      "|  6| sadness| .Couldnt wait to...|Couldnt wait live...|  1.0|[, .couldnt, wait...|[, .couldnt, wait...|(49719,[0,19,26,3...|[-96.231119794613...|[0.03649482173272...|       1.0|\n",
      "|  8|surprise|En dan krijg je f...|En dan krijg je f...|  4.0|[en, dan, krijg, ...|[en, dan, krijg, ...|(49719,[48,106,17...|[-87.471326141878...|[3.39617569395329...|       4.0|\n",
      "| 13|    fear|Against the assau...|assault laughter ...|  2.0|[against, the, as...|[assault, laughte...|(49719,[146,558,9...|[-69.407223315272...|[0.74258535452323...|       0.0|\n",
      "| 19|surprise|@JuliaLeader I re...|  reeeeeellllyyyy...|  4.0|[@julialeader, i,...|[@julialeader, re...|(49719,[13,90,137...|[-77.944478298806...|[0.69946036633300...|       0.0|\n",
      "| 23|   anger|I have to talk to...|               talk |  3.0|[i, have, to, tal...|           [talk, !]|(49719,[4,197],[1...|[-15.699845946269...|[0.27605221648173...|       3.0|\n",
      "| 29|     joy|When I was select...|selected study un...|  0.0|[when, i, was, se...|[selected, study,...|(49719,[261,787,1...|[-25.072226594921...|[0.98933677032297...|       0.0|\n",
      "| 35|     joy|When I passed the...|passed BA exams c...|  0.0|[when, i, passed,...|[passed, b.a, exa...|(49719,[30,151,18...|[-50.598917518034...|[0.98571189412063...|       0.0|\n",
      "| 45|    fear|&quot;The family ...|quotThe family be...|  2.0|[&quot;the, famil...|[&quot;the, famil...|(49719,[111,659,1...|[-82.045501390812...|[0.79385162483099...|       0.0|\n",
      "| 46| sadness|Bro team lost... ...|Bro team lost  pl...|  1.0|[bro, team, lost....|[bro, team, lost....|(49719,[384,573,8...|[-57.833815328898...|[0.54426125248298...|       0.0|\n",
      "| 47|     joy|When I heard that...|heard selected fo...|  0.0|[when, i, heard, ...|[heard, selected,...|(49719,[0,30,99,1...|[-99.143305346861...|[0.99949114093577...|       0.0|\n",
      "| 49|     joy|Welp time to stud...|Welp time study days|  0.0|[welp, time, to, ...|[welp, time, stud...|(49719,[7,64,261,...|[-40.688796261128...|[0.99491633278238...|       0.0|\n",
      "| 51|    fear|My own dismay at ...|dismay way kids s...|  2.0|[my, own, dismay,...|[dismay, way, kid...|(49719,[1,18,60,4...|[-84.365736000387...|[0.00465001691328...|       2.0|\n",
      "| 55| sadness|I apparently lost...|apparently lost b...|  1.0|[i, apparently, l...|[apparently, lost...|(49719,[157,703],...|[-18.355261591103...|[0.25205466365493...|       1.0|\n",
      "| 62|     joy| I am feeling awe...|    feeling awesome |  0.0|[, i, am, feeling...|[, feeling, aweso...|(49719,[0,1,65,93...|[-25.175300618480...|[0.80494621407231...|       0.0|\n",
      "| 69|    fear|Not applicable to...|   applicable myself|  2.0|[not, applicable,...|[applicable, myse...|(49719,[1394],[1.0])|[-10.746300012858...|[0.36061985809837...|       0.0|\n",
      "| 77|   anger|Side effect of no...|effect smoking re...|  3.0|[side, effect, of...|[side, effect, sm...|(49719,[465,1664,...|[-31.330894108424...|[0.11525780622286...|       2.0|\n",
      "|100|     joy|If you are robbed...|robbed tribulatio...|  0.0|[if, you, are, ro...|[robbed, tribulat...|(49719,[37,115,15...|[-102.58231088555...|[0.99954987521972...|       0.0|\n",
      "|112|    fear|I can not wait ti...|wait till factor ...|  2.0|[i, can, not, wai...|[wait, till, fact...|(49719,[9,123,136...|[-57.595451232678...|[0.75969795399271...|       0.0|\n",
      "|116|    fear|Nearly a year lat...|Nearly year later...|  2.0|[nearly, a, year,...|[nearly, year, la...|(49719,[0,99,139,...|[-94.249715005037...|[0.90263920034866...|       0.0|\n",
      "+---+--------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f19143dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'Emotion',\n",
       " 'Text',\n",
       " 'Clean_Text',\n",
       " 'label',\n",
       " 'token_text',\n",
       " 'filter_token',\n",
       " 'raw_Features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Columns\n",
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe3896d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:50 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "22/11/24 16:30:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n",
      "+--------------------+--------------------+--------+-----+----------+\n",
      "|       rawPrediction|         probability| Emotion|label|prediction|\n",
      "+--------------------+--------------------+--------+-----+----------+\n",
      "|[-69.525503433815...|[0.60336336801864...| sadness|  1.0|       0.0|\n",
      "|[-96.231119794613...|[0.03649482173272...| sadness|  1.0|       1.0|\n",
      "|[-87.471326141878...|[3.39617569395329...|surprise|  4.0|       4.0|\n",
      "|[-69.407223315272...|[0.74258535452323...|    fear|  2.0|       0.0|\n",
      "|[-77.944478298806...|[0.69946036633300...|surprise|  4.0|       0.0|\n",
      "+--------------------+--------------------+--------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('rawPrediction','probability','Emotion','label','prediction').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913bd201",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "+ Accuracy\n",
    "+ Precision\n",
    "+ F1score\n",
    "\n",
    "### Method 1 - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffff5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c2fc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78c7e8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:51 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "22/11/24 16:30:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Emotion, Text, Clean_Text\n",
      " Schema: _c0, Emotion, Text, Clean_Text\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/srijanaraut/Downloads/NLP-Text-Emotion-main/end2end-nlp-project/notebooks/data/emotion_dataset_2.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6008373033059045"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fdee464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 16:30:51 ERROR Instrumentation: java.io.IOException: Path models/pyspark_nb_model_24_Nov_2022 already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n",
      "\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n",
      "\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n",
      "\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n",
      "\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o429.save.\n: java.io.IOException: Path models/pyspark_nb_model_24_Nov_2022 already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Saving Model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m modelPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/pyspark_nb_model_24_Nov_2022\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelPath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/pyspark/ml/util.py:246\u001b[0m, in \u001b[0;36mMLWritable.save\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124;03m\"\"\"Save this ML instance to the given path, a shortcut of 'write().save(path)'.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/pyspark/ml/util.py:197\u001b[0m, in \u001b[0;36mJavaMLWriter.save\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath should be a string, got type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(path))\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o429.save.\n: java.io.IOException: Path models/pyspark_nb_model_24_Nov_2022 already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n"
     ]
    }
   ],
   "source": [
    "# Saving Model\n",
    "modelPath = \"models/pyspark_nb_model_24_Nov_2022\"\n",
    "model.save(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e39ad6a",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = predictions.select('label')\n",
    "y_true = y_true.toPandas()\n",
    "y_pred = predictions.select('prediction')\n",
    "y_pred = y_pred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a318f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aab4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d289db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b247918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['joy', 'sadness', 'fear', 'anger', 'surprise', 'neutral', 'disgust', 'shame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fa435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classication Report\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c22ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classication Report\n",
    "print(classification_report(y_true,y_pred,target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
